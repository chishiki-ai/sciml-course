{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503d68cb-6f14-4412-87d1-81e8cf0c0e80",
   "metadata": {},
   "source": [
    "# CNN Part 2: Building a CNN Classifier with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dff51b-0811-4fb7-9c8f-3fdf91cabbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.hub.set_dir(os.environ['WORK'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918606b",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1078a",
   "metadata": {},
   "source": [
    "Download the dataset to `$WORK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082548c-2af8-44bb-8cac-f7f1fe291d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cp /work2/10000/zw427/data.tar.gz $WORK\n",
    "! tar zxf $WORK/data.tar.gz -C $WORK\n",
    "! ls $WORK/Dataset_2\n",
    "! rm $WORK/data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce726213",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e8570-3b2e-46b2-9f12-cc2aae12a9d1",
   "metadata": {},
   "source": [
    "This notebook will use the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb96e6-0599-40da-b9a1-7919a86f5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\"lr\":1e-4, \"batch_size\":16, \"epochs\":5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba05f1-3a0b-42dd-aad8-993d81fbf0cf",
   "metadata": {},
   "source": [
    "## Dataset Loaders and Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c17efa-d8a0-48c2-9d38-37b3b96959fa",
   "metadata": {},
   "source": [
    "Define the path to our train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23723fe-5f43-4c9f-ada9-4c4a411372f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(os.environ['WORK'], \"Dataset_2/Train/\")\n",
    "val_path   = os.path.join(os.environ['WORK'], \"Dataset_2/Validation/\")\n",
    "test_path  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eb1cf",
   "metadata": {},
   "source": [
    "Define a dataset loader. The transformation is different from part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b9188-65e3-40e4-a01a-77c325731a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(train_path, val_path, test_path):\n",
    "    val_img_transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                         transforms.ToTensor()])\n",
    "    \n",
    "    #################################################\n",
    "    ##################### TODO ######################  \n",
    "\n",
    "    #  Main Modification: Additional transformation\n",
    "    train_img_transform =\n",
    " \n",
    "    #################################################\n",
    "    #################### ANSWER #####################\n",
    "    \n",
    "    # train_img_transform = transforms.Compose([transforms.AutoAugment(),\n",
    "    #                                            transforms.Resize((244,244)),\n",
    "    #                                            transforms.ToTensor()])\n",
    "    \n",
    "    #################################################\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=train_img_transform)\n",
    "    val_dataset = datasets.ImageFolder(val_path, transform=val_img_transform) \n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=val_img_transform) if test_path is not None else None\n",
    "    print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4236ed-3e7a-4a29-802f-a5f23236670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c2197-0d1a-4cf1-ab6a-9eaf01df2e5e",
   "metadata": {},
   "source": [
    "## Construct Dataloaders \n",
    "Define a dataloader constructor in the same way as part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36426e-e6a8-4015-a953-a9976d1df230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size, shuffle)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size) \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size) if test_path is not None else None\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf912a3-503d-4e72-b690-71f66ee8c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213bc121-cb8f-495a-8177-dcf8521a9ed8",
   "metadata": {},
   "source": [
    "## Visualizing the Design Safe Dataset\n",
    "\n",
    "Before moving on to building CNN models, visualize the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e288c97-fddf-4901-afdd-999e163a8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(3,3,figsize=(8, 8))\n",
    "label_map={0: 'low damage', 1:'medium damage', 2:'high damage'}\n",
    "for ax in axs.ravel():\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    ax.imshow(img.permute(1, 2, 0)) #.reshape((244,244,3)))\n",
    "    ax.set_title(label_map[label])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb38ef5-8dc3-481b-a722-5b6fc59334b8",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "### ResNet and Transfer Learning\n",
    "Instantiate a model with resnet34's pretrained weights and create a new fully connected final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a008a8-1c24-4d0a-9018-2cb6471b755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResNet():\n",
    "    resnet = models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "    # Fix the conv layers parameters\n",
    "    for conv_param in resnet.parameters():\n",
    "        conv_param.require_grad = False\n",
    "\n",
    "    # get the input dimension for this layer\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    \n",
    "    # build the new final mlp layers of network\n",
    "    fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, num_ftrs),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_ftrs, 3)\n",
    "    )\n",
    "    \n",
    "    # replace final fully connected layer\n",
    "    resnet.fc = fc\n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc3cae-86ce-499c-acda-118fd823b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = getResNet()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2553a5-cb47-4c52-b431-60562f110db2",
   "metadata": {},
   "source": [
    "### Check for GPU and move model to correct device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c6175-c929-4bd5-8dd5-e436816c2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebb8f0",
   "metadata": {},
   "source": [
    "Pass resnet model to gpu (or cpu if gpu is not found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5268b3-21c7-4223-8ecf-c5c89ae63d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad3042",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n",
    "\n",
    "### Define Loss Function, Optimizer, and Label smoothing\n",
    "Same optimizer and loss functions as part 1, but add label smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(resnet.parameters(),lr=hp[\"lr\"])\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf44d061-6c02-4d8f-8c6f-7a1f9858de1c",
   "metadata": {},
   "source": [
    "### Reduced learning rate on plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036896fe-9ab4-4ca0-8d7e-2a0f8dec945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "##################### TODO ######################\n",
    "    \n",
    "# Add a learning rate scheduler so that the learning rate can change throughout the optimization procedure\n",
    "\n",
    "scheduler = \n",
    "    \n",
    "#################################################\n",
    "############### POSSIBLE ANSWER #################\n",
    "    \n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, \n",
    "#                                                        mode='min',\n",
    "#                                                        factor=0.1, \n",
    "#                                                        patience=2,\n",
    "#                                                        min_lr=1e-8)\n",
    "    \n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea427ba3-d5f0-4d10-b02a-18730c866482",
   "metadata": {},
   "source": [
    "### Setting up Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cbada-157b-4a55-9a3e-ebc7ffbc3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, DEVICE):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(DEVICE))\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8f8fa",
   "metadata": {},
   "source": [
    "Create a directory to store models and define a file name for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60620aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving the trained model\n",
    "model_folder_path = os.path.join(os.environ['WORK'], \"cnn2_output_model\") \n",
    "os.makedirs(model_folder_path,exist_ok=True)\n",
    "\n",
    "# filename for the best model\n",
    "checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16593e12",
   "metadata": {},
   "source": [
    "To resume the training process, run this code to load the best previous accuracy, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ffde4-6e02-4975-9314-0ae1d7b7875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint that has the best performance in previous experiments\n",
    "prev_best_val_acc = None\n",
    "checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint = load_checkpoint(checkpoint_file, device)\n",
    "    prev_best_val_acc = checkpoint['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5b3ce-4196-4b4a-89a4-fdb4a26d1762",
   "metadata": {},
   "source": [
    "### Train and Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d6320-a919-4f88-b560-618059d160fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(data_loader, model, loss_fn, DEVICE):\n",
    "    model.eval()\n",
    "    loss, accuracy = 0.0, 0.0\n",
    "    n = len(data_loader)\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        x,y = data\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x)\n",
    "        loss += loss_fn(pred, y)/len(x)\n",
    "        pred_label = torch.argmax(pred, axis = 1)\n",
    "        accuracy += torch.sum(pred_label == y)/len(x)\n",
    "\n",
    "    return loss/n, accuracy/n \n",
    "\n",
    "def train(train_loader, val_loader, model, opt, scheduler, loss_fn, epochs, DEVICE, checkpoint_file, prev_best_val_acc):\n",
    "    n = len(train_loader)\n",
    "  \n",
    "    best_val_acc = torch.tensor(0.0).to(DEVICE) if prev_best_val_acc is None else prev_best_val_acc\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)\n",
    "    \n",
    "        avg_loss, val_loss, val_acc, avg_acc  = 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "        start_time = datetime.now()\n",
    "    \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred,y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            avg_loss += loss.item()/len(x)\n",
    "            pred_label = torch.argmax(pred, axis=1)\n",
    "            avg_acc += torch.sum(pred_label == y)/len(x)\n",
    "\n",
    "        val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
    "    \n",
    "        end_time = datetime.now()\n",
    "    \n",
    "        total_time = torch.tensor((end_time-start_time).seconds).to(DEVICE)\n",
    "    \n",
    "        #################################################\n",
    "        ##################### TODO ######################\n",
    "\n",
    "        # Learning rate reducer takes action\n",
    "\n",
    "        #################################################\n",
    "        #################### ANSWER #####################\n",
    "\n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "        #################################################\n",
    "        \n",
    "        print(f'lr for this epoch is {scheduler.get_last_lr()}')\n",
    "    \n",
    "        avg_loss, avg_acc = avg_loss/n, avg_acc/n\n",
    "    \n",
    "    \n",
    "        if val_acc.item() > best_val_acc.item():\n",
    "            print(f\"\\nPrev Best Val Acc: {best_val_acc} < Cur Val Acc: {val_acc}\")\n",
    "            print(\"Saving the new best model...\")\n",
    "            \n",
    "            #################################################\n",
    "            ##################### TODO ######################\n",
    "\n",
    "            # Save the best model that has the highest val accuracy\n",
    "\n",
    "            torch.save({})\n",
    "            \n",
    "            #################################################\n",
    "            #################### ANSWER #####################\n",
    "\n",
    "            # torch.save({\n",
    "            #    'epoch':epoch,\n",
    "            #    'model_state_dict':model.state_dict(),\n",
    "            #    'accuracy':val_acc,\n",
    "            #    'loss':val_loss\n",
    "            # }, checkpoint_file)\n",
    "\n",
    "            #################################################\n",
    "    \n",
    "            best_val_acc = val_acc\n",
    "            print(\"Finished saving model\\n\")\n",
    "        \n",
    "        # Print the metrics (should be same on all machines)\n",
    "        print(f\"\\n(Epoch {epoch+1}/{epochs}) Time: {total_time}s\")\n",
    "        print(f\"(Epoch {epoch+1}/{epochs}) Average train loss: {avg_loss}, Average train accuracy: {avg_acc}\")\n",
    "        print(f\"(Epoch {epoch+1}/{epochs}) Val loss: {val_loss}, Val accuracy: {val_acc}\")  \n",
    "        print(f\"(Epoch {epoch+1}/{epochs}) Current best val acc: {best_val_acc}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564af222-bef4-4d3f-b16a-64906739ab93",
   "metadata": {},
   "source": [
    "### Train Model \n",
    "Task: Monitor Val accuracy vs. Train accuracy and check if overfitting exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3535d9-c157-4edb-aded-5c10bd54b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataloader, val_dataloader, resnet, opt, scheduler,loss_fn, hp[\"epochs\"], device, checkpoint_file, prev_best_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-structure",
   "metadata": {},
   "source": [
    "###  Optional Exercise\n",
    "Above, you trained a ResNet34 model with data augmentation, label smoothing, and learning rate reducer. Try to train the model without these techniques, and compare the training speed and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "##################### TODO ######################\n",
    "    \n",
    "# Do not use torch.save\n",
    "# It may override your previous model \n",
    "    \n",
    "#################################################\n",
    "############### POSSIBLE ANSWER #################\n",
    "\n",
    "# def load_datasets(train_path, val_path, test_path):\n",
    "#     val_img_transform = transforms.Compose([transforms.Resize((244, 244)),\n",
    "#                                             transforms.ToTensor()])\n",
    "#     train_img_transform = transforms.Compose([transforms.Resize((244, 244)),\n",
    "#                                               transforms.ToTensor()])\n",
    "#     train_dataset = datasets.ImageFolder(train_path, transform=train_img_transform)\n",
    "#     val_dataset = datasets.ImageFolder(val_path, transform=val_img_transform)\n",
    "#     test_dataset = datasets.ImageFolder(test_path, transform=val_img_transform) if test_path is not None else None\n",
    "#     print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "#     return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "# train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)\n",
    "\n",
    "# def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):\n",
    "#     train_dataloader = torch.utils.data.DataLoader(train_set, batch_size, shuffle)\n",
    "#     val_dataloader = torch.utils.data.DataLoader(val_set, batch_size)\n",
    "#     test_dataloader = torch.utils.data.DataLoader(test_set, batch_size) if test_set is not None else None\n",
    "#     return train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "# train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)\n",
    "\n",
    "# resnet = getResNet()\n",
    "# resnet.to(device)\n",
    "\n",
    "# opt = torch.optim.Adam(resnet.parameters(), lr=hp[\"lr\"])\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# def train(train_loader, val_loader, model, opt, loss_fn, epochs, DEVICE):\n",
    "#     n = len(train_loader)\n",
    "    \n",
    "#     best_val_acc = torch.tensor(0.0).to(DEVICE)\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         model.train(True)\n",
    "        \n",
    "#         avg_loss, val_loss, val_acc, avg_acc = 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "#         start_time = datetime.now()\n",
    "        \n",
    "#         for x, y in train_loader:\n",
    "#             x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "#             pred = model(x)\n",
    "#             loss = loss_fn(pred, y)\n",
    "            \n",
    "#             opt.zero_grad()\n",
    "#             loss.backward()\n",
    "#             opt.step()\n",
    "            \n",
    "#             avg_loss += loss.item() / len(x)\n",
    "#             pred_label = torch.argmax(pred, axis=1)\n",
    "#             avg_acc += torch.sum(pred_label == y) / len(x)\n",
    "        \n",
    "#         val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
    "        \n",
    "#         end_time = datetime.now()\n",
    "        \n",
    "#         total_time = torch.tensor((end_time - start_time).seconds).to(DEVICE)\n",
    "        \n",
    "#         avg_loss, avg_acc = avg_loss / n, avg_acc / n\n",
    "        \n",
    "#         # Print the metrics (should be same on all machines)\n",
    "#         print(f\"\\n(Epoch {epoch + 1}/{epochs}) Time: {total_time}s\")\n",
    "#         print(f\"(Epoch {epoch + 1}/{epochs}) Average train loss: {avg_loss}, Average train accuracy: {avg_acc}\")\n",
    "#         print(f\"(Epoch {epoch + 1}/{epochs}) Val loss: {val_loss}, Val accuracy: {val_acc}\")\n",
    "\n",
    "# train(train_dataloader, val_dataloader, resnet, opt, loss_fn, hp[\"epochs\"], device)\n",
    "    \n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a5cd8",
   "metadata": {},
   "source": [
    "## Load the Best Model and Explore Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-watch",
   "metadata": {},
   "source": [
    "### Read the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce4b48-3f26-4f67-adc7-b54103eab4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, DEVICE):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model_fm_checkpoint(checkpoint, primitive_model, DEVICE):\n",
    "    primitive_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return primitive_model.to(DEVICE)\n",
    "\n",
    "def getResNet():\n",
    "    resnet = models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "    # Fix the conv layers parameters\n",
    "    for conv_param in resnet.parameters():\n",
    "        conv_param.require_grad = False\n",
    "\n",
    "    # get the input dimension for this layer\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    \n",
    "    # build the new final mlp layers of network\n",
    "    fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, num_ftrs),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_ftrs, 3)\n",
    "    )\n",
    "    \n",
    "    # replace final fully connected layer\n",
    "    resnet.fc = fc\n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_dump_dir = checkpoint_file\n",
    "model = None\n",
    "\n",
    "try:\n",
    "    ckpt = load_checkpoint(model_dump_dir, DEVICE)\n",
    "    model = load_model_fm_checkpoint(ckpt, getResNet(), DEVICE)\n",
    "except FileNotFoundError: \n",
    "    print(f\"{model_dump_dir} does not exist, please first train the model before performing inference!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-sheffield",
   "metadata": {},
   "source": [
    "###  Load in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_datasets(test_path):\n",
    "    img_transform = transforms.Compose([transforms.Resize((244,244)),transforms.ToTensor()])\n",
    "    try:\n",
    "        test_dataset = datasets.ImageFolder(test_path, transform=img_transform) \n",
    "    except:\n",
    "        print(f\"test_path: {test_path} does not exist!\")\n",
    "    print(f\"Test set size: {len(test_dataset)}\")\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path   = os.path.join(os.environ['WORK'], \"Dataset_2/Validation/\")\n",
    "test_set = load_test_datasets(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-accent",
   "metadata": {},
   "source": [
    "### Perform Inference on a Random Image\n",
    "\n",
    "Tasks:\n",
    "1. See if predictions match labels\n",
    "2. Randomly choose images and run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = torch.randint(0, len(test_set), size=(1,1))\n",
    "sample_image, label = test_set[random_idx]\n",
    "plt.imshow(sample_image.permute(1,2,0))\n",
    "plt.show()\n",
    "print(f\"label: {label} for image_idx: {random_idx}\")\n",
    "\n",
    "sample = sample_image.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "#################################################\n",
    "##################### TODO ######################\n",
    "    \n",
    "# Make predictions with the model\n",
    "\n",
    "prediction = \n",
    "    \n",
    "#################################################\n",
    "#################### ANSWER #####################\n",
    "    \n",
    "# prediction = torch.argmax(model(sample))\n",
    "    \n",
    "#################################################\n",
    "\n",
    "print(f\"prediction result: {prediction} actual result: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
