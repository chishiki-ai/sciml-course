{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503d68cb-6f14-4412-87d1-81e8cf0c0e80",
   "metadata": {},
   "source": [
    "# CNN Part 1: Building a CNN Classifier with PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dff51b-0811-4fb7-9c8f-3fdf91cabbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.hub.set_dir(os.environ['SCRATCH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19874c",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1eaec3",
   "metadata": {},
   "source": [
    "Copy the DesignSafe dataset to your `$SCRATCH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /work2/10000/zw427/data.tar.gz $SCRATCH\n",
    "! tar zxf $SCRATCH/data.tar.gz -C $SCRATCH\n",
    "! ls $SCRATCH/Dataset_2\n",
    "! rm $SCRATCH/data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce726213",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e8570-3b2e-46b2-9f12-cc2aae12a9d1",
   "metadata": {},
   "source": [
    "This notebook will use the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb96e6-0599-40da-b9a1-7919a86f5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\"lr\":1e-4, \"batch_size\":16, \"epochs\":5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba05f1-3a0b-42dd-aad8-993d81fbf0cf",
   "metadata": {},
   "source": [
    "## Dataset Loaders and Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c17efa-d8a0-48c2-9d38-37b3b96959fa",
   "metadata": {},
   "source": [
    "Define the path to our train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23723fe-5f43-4c9f-ada9-4c4a411372f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Train/\")\n",
    "val_path   = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Validation/\")\n",
    "test_path  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eb1cf",
   "metadata": {},
   "source": [
    "Define a dataset loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b9188-65e3-40e4-a01a-77c325731a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(train_path, val_path, test_path):\n",
    "\n",
    "    # define the transformations\n",
    "    img_transform = transforms.Compose([transforms.Resize((244,244)),transforms.ToTensor()])\n",
    "    \n",
    "    # load data\n",
    "    train_dataset = train_dataset = datasets.ImageFolder(train_path, transform=img_transform)\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(val_path, transform=img_transform) \n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=img_transform) if test_path is not None else None\n",
    "    print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4236ed-3e7a-4a29-802f-a5f23236670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c2197-0d1a-4cf1-ab6a-9eaf01df2e5e",
   "metadata": {},
   "source": [
    "## Construct Dataloaders "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562b29b",
   "metadata": {},
   "source": [
    "Define a dataloader constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36426e-e6a8-4015-a953-a9976d1df230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):\n",
    "    \n",
    "    # instantate the DataLoader\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size, shuffle)\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size) \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size) if test_path is not None else None\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf912a3-503d-4e72-b690-71f66ee8c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213bc121-cb8f-495a-8177-dcf8521a9ed8",
   "metadata": {},
   "source": [
    "## Visualizing the Design Safe Dataset\n",
    "\n",
    "Before moving on to building the CNN models, visualize the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e288c97-fddf-4901-afdd-999e163a8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(3,3,figsize=(8, 8))\n",
    "label_map={0: 'low damage', 1:'medium damage', 2:'high damage'}\n",
    "for ax in axs.ravel():\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    ax.imshow(img.permute(1, 2, 0)) #.reshape((244,244,3)))\n",
    "    ax.set_title(label_map[label])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb38ef5-8dc3-481b-a722-5b6fc59334b8",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "### ResNet\n",
    "Instantiate a model with resnet's pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc3cae-86ce-499c-acda-118fd823b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(weights=\"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bf221-1841-4896-b685-9c62dbbed91e",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "Freezing all the weights of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241bfcc-6796-42c4-b183-a70b75518f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e7e2b-b09f-4557-a745-44216997dc67",
   "metadata": {},
   "source": [
    "Print last fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8398f58-6686-4aad-ba69-62521356e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8c7b4",
   "metadata": {},
   "source": [
    "Add a new final fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b01b4-3385-4931-b19e-9a013fe59b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input dimension for this layer\n",
    "num_ftrs = resnet.fc.in_features\n",
    "\n",
    "# build the new final fully connected layers of network\n",
    "fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, num_ftrs),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_ftrs, 3),\n",
    ")\n",
    "\n",
    "# replace final fully connected layer\n",
    "resnet.fc = fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf44d061-6c02-4d8f-8c6f-7a1f9858de1c",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n",
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036896fe-9ab4-4ca0-8d7e-2a0f8dec945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(resnet.parameters(),lr=hp[\"lr\"])\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620a600-47e7-4663-8ad7-fd62bc79f9d0",
   "metadata": {},
   "source": [
    "Note that the learning rate hyperparameter is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28167cce-957a-48f6-bbeb-c767e0f68cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5b3ce-4196-4b4a-89a4-fdb4a26d1762",
   "metadata": {},
   "source": [
    "### Train and Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d6320-a919-4f88-b560-618059d160fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(data_loader, model, loss_fn, DEVICE):\n",
    "    model.eval()\n",
    "    loss, accuracy = 0.0, 0.0\n",
    "    n = len(data_loader)\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        x,y = data\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x)\n",
    "        loss += loss_fn(pred, y)/len(x)\n",
    "        pred_label = torch.argmax(pred, axis = 1)\n",
    "        accuracy += torch.sum(pred_label == y)/len(x)\n",
    "    \n",
    "    return loss/n, accuracy/n \n",
    "\n",
    "def train(train_loader, val_loader, model, opt, loss_fn, epochs, DEVICE):\n",
    "    n = len(train_loader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)\n",
    "        count = 0\n",
    "        avg_loss, avg_acc = 0.0, 0.0\n",
    "        count = 0\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        start_time = datetime.now()\n",
    "        for x, y in train_loader:\n",
    "\n",
    "            # move data to gpu\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            # compute model prediction\n",
    "            pred = model(x)\n",
    "\n",
    "            # compute model loss\n",
    "            loss = loss_fn(pred,y)\n",
    "\n",
    "            ## backpropogation\n",
    "            # reset gradient calculations\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update model parameters via optimization step\n",
    "            opt.step()\n",
    "            \n",
    "            avg_loss += loss\n",
    "            pred_label = torch.argmax(pred, axis=1)\n",
    "            avg_acc += torch.sum(pred_label == y)/len(x)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        print(f\"Time: {(end_time-start_time).seconds}s\")\n",
    "        print(f\"Average train loss: {avg_loss/n}, Average train accuracy: {avg_acc/n}\")\n",
    "        val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
    "        print(f\"Val loss: {val_loss}, Val accuracy: {val_acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ad6be-a4f9-4cf7-ac9c-063518fa80bd",
   "metadata": {},
   "source": [
    "### Check for GPU and move model to correct device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd200d93-befa-41ed-8027-31f46ebb94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc34881",
   "metadata": {},
   "source": [
    "Pass resnet model to gpu (or cpu if gpu is not found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f58d3-2759-4234-822a-11042d9b492d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564af222-bef4-4d3f-b16a-64906739ab93",
   "metadata": {},
   "source": [
    "### Train Model \n",
    "Tasks:\n",
    "1. Monitor Val accuracy change along epochs\n",
    "2. Monitor Val accuracy vs. train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3535d9-c157-4edb-aded-5c10bd54b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataloader, val_dataloader, resnet, opt, loss_fn, hp[\"epochs\"], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-sweet",
   "metadata": {},
   "source": [
    "##  Additional Exercise\n",
    "\n",
    "Above, you trained a ResNet18 model with hyperparameters with learning rate 1e-4 for 5 epochs. Try to train the model with learning rate 1e-5 and 1e-3, and compare the training speed and performance. Which is the best learning rate: 1e-5, 1e-4 or 1e-3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [1e-5, 1e-3]:\n",
    "    hp[\"lr\"] = lr\n",
    "    opt = torch.optim.Adam(resnet.parameters(), lr=hp[\"lr\"])\n",
    "    print(hp)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    resnet = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    resnet.to(device)\n",
    "    print(f\"start training with learning rate {lr}\")\n",
    "    train(train_dataloader, val_dataloader, resnet, opt, loss_fn, hp[\"epochs\"], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
