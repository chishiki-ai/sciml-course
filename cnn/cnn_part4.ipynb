{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e805597",
   "metadata": {},
   "source": [
    "# CNN Part 4: Single Node MultiGPU Training with Torchrun "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470907f",
   "metadata": {},
   "source": [
    "## Using Torchrun \n",
    "Code below will modify the MNIST example to be run by torchrun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af9480",
   "metadata": {},
   "source": [
    "### Modify code for environment variables set by torchrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# A. Remove code that sets environment variables as this done for you automatically with torchrun.\n",
    "def init_distributed():\n",
    "\n",
    "    # B. Instead, use these environment variables set by pytorch and instead of explicitly defining them.\n",
    "    world_size = int(os.environ['WORLD_SIZE'])\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    dist.init_process_group(\"nccl\",\n",
    "                            rank=local_rank,\n",
    "                            world_size=world_size)\n",
    "\n",
    "def main():\n",
    "    #####################################################################\n",
    "    # B. We also create the variable local_rank in our main function as well as call the new init_distributed()\n",
    "    # this will be used to assign the gpu where our model should reside as highlighted below \n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "    init_distributed()\n",
    "    ################################################\n",
    "    # .....\n",
    "    # instantiate network and set to local_rank device\n",
    "    net = Net().to(local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1334192",
   "metadata": {},
   "source": [
    "### Add code for writing checkpoints and resuming training after failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee27c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    init_distributed()\n",
    "\n",
    "    train_dataloader = prepare_data()\n",
    "\n",
    "    ################################################                                                 \n",
    "    # A. Create location to store checkpoints\n",
    "\n",
    "    # Create directory for storing checkpointed model\n",
    "    model_folder_path = os.path.join(os.environ['SCRATCH'], \"cnn4_mnist_output_model\") # create variable for path to folder for checkpoints\n",
    "    os.makedirs(model_folder_path,exist_ok=True)                         # create directory for models if they do not exist\n",
    "    \n",
    "    # create file name for checkpoint \n",
    "    checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")   # create filename for model checkpoint\n",
    "    ################################################\n",
    "\n",
    "    net = Net().to(local_rank)\n",
    "\n",
    "    #################################################\n",
    "    # 2B. Read checkpoints if they exist \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)  # load previous checkpoint\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])  # set model weights to be that of the last checkpoint\n",
    "        epoch_start = checkpoint['epoch']                      # set epoch where training should resume\n",
    "   \n",
    "    # otherwise we are starting training from the beginning at epoch 0\n",
    "    else:\n",
    "        epoch_start = 0\n",
    "    ################################################\n",
    "\n",
    "    model = DDP(net,\n",
    "            device_ids=[local_rank],                  # list of gpu that model lives on \n",
    "            output_device=local_rank,                 # where to output model\n",
    "        )\n",
    "\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    save_every = 1\n",
    "    epochs = 10\n",
    "    ###########################################################\n",
    "    # 2C. Resume training at epoch last checkpoint was written\n",
    "    for epoch in range(epoch_start, epochs):                  # note we start loop at epoch_start defined in code above\n",
    "    ###########################################################\n",
    "        train_loop(rank, train_dataloader, model, loss_fn, optimizer)\n",
    "        ###########################################################\n",
    "        # 2D. Write checkpoints periodically during training\n",
    "        if rank == 0 and epoch%save_every==0:\n",
    "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "            torch.save({                                     # save model's state_dict and current epoch periodically\n",
    "                'epoch':epoch,\n",
    "                'model_state_dict':model.module.state_dict(),\n",
    "            }, checkpoint_file)\n",
    "            print(\"Finished saving model\\n\")\n",
    "        ###########################################################\n",
    "\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6887b5",
   "metadata": {},
   "source": [
    "## Launching jobs with Torchrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9f37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# helper functions to display python scripts in Markdown\n",
    "display_python = lambda x: Markdown(f\"```python\\n{Path(x).read_text()}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f44c33",
   "metadata": {},
   "source": [
    "Remove the model from $SCRATCH if you would like to start from epoch 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17930e8",
   "metadata": {},
   "source": [
    "`display_python` displays `cnn_part4/mnist_torchrun.py` with Python syntax highlighting as the cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c22fedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "import torch.distributed as dist\n",
       "import torch \n",
       "from torch.utils.data import DataLoader\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import torch.multiprocessing as mp\n",
       "import os\n",
       "from torch.utils.data.distributed import DistributedSampler\n",
       "import torchvision\n",
       "import torch.nn as nn\n",
       "import torch.nn.functional as F\n",
       "\n",
       "\n",
       "class Net(nn.Module):\n",
       "    def __init__(self):\n",
       "        super(Net, self).__init__()\n",
       "        self.flatten = torch.nn.Flatten()\n",
       "        self.linear_relu_stack = torch.nn.Sequential(\n",
       "            torch.nn.Linear(28*28, 128),\n",
       "            torch.nn.ReLU(),\n",
       "            torch.nn.Dropout(0.2),\n",
       "            torch.nn.Linear(128, 10),\n",
       "        )\n",
       "\n",
       "    def forward(self, x):\n",
       "        x = self.flatten(x)\n",
       "        prob = self.linear_relu_stack(x)\n",
       "        return prob\n",
       "\n",
       "# Remove rank and world_size -- use what's in \n",
       "def prepare_data(batch_size=32):\n",
       "\n",
       "    trainset = torchvision.datasets.MNIST(\n",
       "                            root=os.path.join(os.environ['SCRATCH'], \"data\"),      # path to where data is stored\n",
       "                            train=True,                                         # specifies if data is train or test\n",
       "                            download=True,                                      # downloads data if not available at root\n",
       "                            transform=torchvision.transforms.ToTensor()         # trasforms both features and targets accordingly\n",
       "                            )\n",
       "\n",
       "    # pass data to the distributed sampler and dataloader \n",
       "    train_dataloader = DataLoader(trainset,\n",
       "                                  shuffle=False,\n",
       "                                  sampler=DistributedSampler(trainset),# num_replicas=world_size, rank=rank),\n",
       "                                  batch_size=batch_size)\n",
       "\n",
       "    return train_dataloader\n",
       "\n",
       "\n",
       "##################################################################################\n",
       "# 1A. Remove code that sets environment variables as this done for you automatically with torchrun.\n",
       "def init_distributed():   #rank, world_size):\n",
       "    # 1B. Instead, use these environment variables set by pytorch and instead of explicitly defining them.\n",
       "    world_size = int(os.environ['WORLD_SIZE'])\n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "    torch.cuda.set_device(local_rank)                       #\n",
       "    dist.init_process_group(\"nccl\",                   # backend being used; nccl typically used with distributed GPU training\n",
       "                            rank=local_rank,                # rank of the current process being used\n",
       "                            world_size=world_size)    # total number of processors being used\n",
       "#############################################################\n",
       "\n",
       "from torch.nn.parallel import DistributedDataParallel as DDP\n",
       "\n",
       "# training loop for one epoch\n",
       "def train_loop(rank, dataloader, model, loss_fn, optimizer):\n",
       "    size = len(dataloader.dataset)\n",
       "    for batch, (X, y) in enumerate(dataloader):\n",
       "        # transfer data to GPU if available\n",
       "        X = X.to(rank)\n",
       "        y = y.to(rank)\n",
       "\n",
       "        # Compute prediction and loss\n",
       "        pred = model(X)\n",
       "        loss = loss_fn(pred, y)\n",
       "        \n",
       "        # Backpropagation\n",
       "        optimizer.zero_grad()\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "\n",
       "        if rank == 0:\n",
       "            if batch % 100 == 0:\n",
       "                loss, current = loss.item(), batch * len(X)\n",
       "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
       "\n",
       "def main():\n",
       "    #####################################################################\n",
       "    # 1.B We also create the variable local_rank in our main function as well as call the new init_distributed()\n",
       "    # this will be used to assign the gpu where our model should reside\n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "\n",
       "    init_distributed()\n",
       "    ################################################\n",
       "\n",
       "    train_dataloader = prepare_data()\n",
       "\n",
       "    ################################################                                                 \n",
       "    # A. Create location to store checkpoints\n",
       "\n",
       "    # Create directory for storing checkpointed model\n",
       "    model_folder_path = os.path.join(os.environ['SCRATCH'], \"cnn4_mnist_output_model\") # create variable for path to folder for checkpoints\n",
       "    os.makedirs(model_folder_path,exist_ok=True)                              # create directory for models if they do not exist\n",
       "    # create file name for checkpoint \n",
       "    checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")        # create filename for model checkpoint\n",
       "    ################################################\n",
       "\n",
       "    # instantiate network and set to local_rank device\n",
       "    net = Net().to(local_rank)\n",
       "    \n",
       "    #################################################\n",
       "    # 2B. Read checkpoints if they exist \n",
       "    if os.path.exists(checkpoint_file):\n",
       "        checkpoint = torch.load(checkpoint_file, map_location=torch.device(local_rank))\n",
       "        net.load_state_dict(checkpoint['model_state_dict'])\n",
       "        epoch_start = checkpoint['epoch']\n",
       "    \n",
       "    # otherwise we are starting training from the beginning at epoch 0\n",
       "    else:\n",
       "        epoch_start = 0\n",
       "    ################################################\n",
       "    \n",
       "    model = DDP(net,\n",
       "            device_ids=[local_rank],                  # list of gpu that model lives on \n",
       "            output_device=local_rank,                 # where to output model\n",
       "        )\n",
       "\n",
       "\n",
       "    loss_fn = torch.nn.CrossEntropyLoss() \n",
       "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
       "\n",
       "    save_every = 1\n",
       "    epochs = 10\n",
       "    ###########################################################\n",
       "    # 2C. Resume training at epoch last checkpoint was written\n",
       "    for epoch in range(epoch_start, epochs): # note we start loop at epoch_start defined in code above\n",
       "    ###########################################################\n",
       "        train_loop(local_rank, train_dataloader, model, loss_fn, optimizer)\n",
       "        ###########################################################\n",
       "        # 2D. Write checkpoints periodically during training\n",
       "        if local_rank == 0 and epoch%save_every==0:\n",
       "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
       "            torch.save({\n",
       "                'epoch':epoch,\n",
       "                'model_state_dict':model.module.state_dict(),\n",
       "            }, checkpoint_file)\n",
       "            print(\"Finished saving model\\n\")\n",
       "    ############################################################\n",
       "\n",
       "    dist.destroy_process_group()\n",
       "    \n",
       "    print(\"Done!\")\n",
       "    return model\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    ############################################################\n",
       "    # 4. Remove using the mp.spawn to parallelize code and replace this with a function call, as this is done automatically by torchrun\n",
       "    ############################################################  \n",
       "    main()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_python(\"cnn_part4/mnist_torchrun.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc-per-node=4 cnn_part4/mnist_torchrun.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e315261",
   "metadata": {},
   "source": [
    "## Additional Exercise\n",
    "\n",
    "Modify `cnn_part4/simple_linear_regression_parallel.py` to be able to use torchrun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb59c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "import torch.distributed as dist\n",
       "import torch \n",
       "from torch.utils.data import DataLoader\n",
       "import numpy as np \n",
       "import matplotlib.pyplot as plt\n",
       "import torch.multiprocessing as mp\n",
       "import os\n",
       "from torch.utils.data.distributed import DistributedSampler\n",
       "from torch.nn.parallel import DistributedDataParallel as DDP\n",
       "\n",
       "\n",
       "##############################################\n",
       "# 1. Create a process group\n",
       "def init_distributed(local_rank, world_size):\n",
       "    '''\n",
       "    local_rank: identifier for pariticular GPU on one node\n",
       "    world: total number of process in a the group\n",
       "    '''\n",
       "    os.environ['MASTER_ADDR'] = 'localhost'           # IP address of rank 0 process\n",
       "    os.environ['MASTER_PORT'] = '12355'               # a free port used to communicate amongst processors\n",
       "    torch.cuda.set_device(local_rank)                 \n",
       "    dist.init_process_group(\"nccl\",                   # backend being used; nccl typically used with distributed GPU training\n",
       "                            rank=local_rank,          # rank of the current process being used\n",
       "                            world_size=world_size)    # total number of processors being used\n",
       "##############################################\n",
       "\n",
       "def get_model():\n",
       "    return torch.nn.Sequential(\n",
       "            torch.nn.Linear(1, 1),     # first number specifies input dimension; second number specifies output dimension\n",
       "            ) \n",
       "\n",
       "def prepare_data(batch_size=32):\n",
       "    # Generate random data centered around 10 with noise\n",
       "    X = torch.randn(32*4, 1) * 10\n",
       "    y = X + torch.randn(32*4, 1) * 3\n",
       "    \n",
       "    # pass data to the distributed sampler and dataloader \n",
       "    train_dataloader = DataLoader(list(zip(X,y)),\n",
       "                                  ##############################################\n",
       "                                  # 2. Use Pytorch's DistributedSampler to ensure that data passed to each GPU is different\n",
       "                                  shuffle=False,\n",
       "                                  sampler=DistributedSampler(list(zip(X,y))),\n",
       "                                  ##############################################\n",
       "                                  batch_size=batch_size)\n",
       "    \n",
       "    return train_dataloader\n",
       "\n",
       "# training loop for one epoch\n",
       "def train_loop(rank, dataloader, model, loss_fn, optimizer):\n",
       "    size = len(dataloader.dataset)\n",
       "    for batch, (X, y) in enumerate(dataloader):\n",
       "        # transfer data to GPU if available\n",
       "        X = X.to(rank)\n",
       "        y = y.to(rank)\n",
       "        \n",
       "        # Compute prediction and loss\n",
       "        pred = model(X)\n",
       "        loss = loss_fn(pred, y)\n",
       "\n",
       "        # Backpropagation\n",
       "        optimizer.zero_grad()\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "\n",
       "        if batch % 2 == 0:\n",
       "            loss, current = loss.item(), batch * len(X)\n",
       "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
       "\n",
       "def main(rank, world_size):\n",
       "    init_distributed(rank, world_size)\n",
       "\n",
       "    train_dataloader = prepare_data()\n",
       "\n",
       "    ##############################################\n",
       "    # 3. Wrap Model with Pytorch's DistributedDataParallel\n",
       "    model = DDP(get_model().to(rank), device_ids=[rank], output_device=rank)\n",
       "    ##############################################\n",
       "    \n",
       "    # instantiate loss and optimizer \n",
       "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
       "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
       "\n",
       "    # Train Model \n",
       "    epochs = 20\n",
       "    for t in range(epochs):\n",
       "        ################################################\n",
       "        # 4. Only write/print model information on one GPU\n",
       "        if rank == 0:\n",
       "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
       "        ################################################\n",
       "        train_loop(rank, train_dataloader, model, loss_fn, optimizer)\n",
       "\n",
       "    #################################################\n",
       "    # 5. Close Process Group\n",
       "    dist.destroy_process_group()\n",
       "    #################################################\n",
       "\n",
       "    print(\"Done!\")\n",
       "    return model\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    world_size= torch.cuda.device_count()\n",
       "    mp.spawn(main, args=(world_size,) , nprocs=world_size)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_python(\"cnn_part4/simple_linear_regression_parallel.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be9158",
   "metadata": {},
   "source": [
    "Below is the modified version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24de4c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "import torch.distributed as dist\n",
       "import torch \n",
       "from torch.utils.data import DataLoader\n",
       "import numpy as np \n",
       "import matplotlib.pyplot as plt\n",
       "import torch.multiprocessing as mp\n",
       "import os\n",
       "from torch.utils.data.distributed import DistributedSampler\n",
       "from torch.nn.parallel import DistributedDataParallel as DDP\n",
       "\n",
       "\n",
       "##############################################\n",
       "# 1. Create a process group\n",
       "def init_distributed():\n",
       "    '''\n",
       "    local_rank: identifier for pariticular GPU on one node\n",
       "    world: total number of process in a the group\n",
       "    '''\n",
       "    world_size = int(os.environ['WORLD_SIZE'])\n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "    torch.cuda.set_device(local_rank)                 \n",
       "    dist.init_process_group(\"nccl\",                   # backend being used; nccl typically used with distributed GPU training\n",
       "                            rank=local_rank,          # rank of the current process being used\n",
       "                            world_size=world_size)    # total number of processors being used\n",
       "##############################################\n",
       "\n",
       "def get_model():\n",
       "    return torch.nn.Sequential(\n",
       "            torch.nn.Linear(1, 1),     # first number specifies input dimension; second number specifies output dimension\n",
       "            ) \n",
       "\n",
       "def prepare_data(batch_size=32):\n",
       "    # Generate random data centered around 10 with noise\n",
       "    X = torch.randn(32*4, 1) * 10\n",
       "    y = X + torch.randn(32*4, 1) * 3\n",
       "    \n",
       "    # pass data to the distributed sampler and dataloader \n",
       "    train_dataloader = DataLoader(list(zip(X,y)),\n",
       "                                  ##############################################\n",
       "                                  # 2. Use Pytorch's DistributedSampler to ensure that data passed to each GPU is different\n",
       "                                  shuffle=False,\n",
       "                                  sampler=DistributedSampler(list(zip(X,y))),\n",
       "                                  ##############################################\n",
       "                                  batch_size=batch_size)\n",
       "    \n",
       "    return train_dataloader\n",
       "\n",
       "# training loop for one epoch\n",
       "def train_loop(rank, dataloader, model, loss_fn, optimizer):\n",
       "    size = len(dataloader.dataset)\n",
       "    for batch, (X, y) in enumerate(dataloader):\n",
       "        # transfer data to GPU if available\n",
       "        X = X.to(rank)\n",
       "        y = y.to(rank)\n",
       "        \n",
       "        # Compute prediction and loss\n",
       "        pred = model(X)\n",
       "        loss = loss_fn(pred, y)\n",
       "\n",
       "        # Backpropagation\n",
       "        optimizer.zero_grad()\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "\n",
       "        if batch % 2 == 0:\n",
       "            loss, current = loss.item(), batch * len(X)\n",
       "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
       "\n",
       "def main():\n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "\n",
       "    init_distributed()\n",
       "\n",
       "    train_dataloader = prepare_data()\n",
       "\n",
       "    ##############################################\n",
       "    # 3. Wrap Model with Pytorch's DistributedDataParallel\n",
       "    model = DDP(get_model().to(local_rank), device_ids=[local_rank], output_device=local_rank)\n",
       "    ##############################################\n",
       "    \n",
       "    # instantiate loss and optimizer \n",
       "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
       "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
       "\n",
       "    # Train Model \n",
       "    epochs = 20\n",
       "    for t in range(epochs):\n",
       "        ################################################\n",
       "        # 4. Only write/print model information on one GPU\n",
       "        if local_rank == 0:\n",
       "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
       "        ################################################\n",
       "        train_loop(local_rank, train_dataloader, model, loss_fn, optimizer)\n",
       "\n",
       "    #################################################\n",
       "    # 5. Close Process Group\n",
       "    dist.destroy_process_group()\n",
       "    #################################################\n",
       "\n",
       "    print(\"Done!\")\n",
       "    return model\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_python(\"cnn_part4/simple_linear_regression_parallel_torchrun.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc-per-node=4 cnn_part4/simple_linear_regression_parallel_torchrun.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea86fe9",
   "metadata": {},
   "source": [
    "## DesignSafe Classifier \n",
    "### Reused code from Part 1 and 2 \n",
    "Below are a set of functions and import statements that can be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to our data.\n",
    "# The datasets transformations are the same as the ones from part 2 of this tutorial.\n",
    "def load_datasets(train_path, val_path, test_path):\n",
    "    val_img_transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                             transforms.ToTensor()])\n",
    "    train_img_transform = transforms.Compose([transforms.AutoAugment(),\n",
    "                                               transforms.Resize((244,244)),\n",
    "                                               transforms.ToTensor()])\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=train_img_transform)\n",
    "    val_dataset = datasets.ImageFolder(val_path, transform=val_img_transform)\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=val_img_transform) if test_path is not None else None\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Building the Neural Network\n",
    "def getResNet():\n",
    "    resnet = models.resnet34(weights='IMAGENET1K_V1')\n",
    "\n",
    "    # Fix the conv layers parameters\n",
    "    for conv_param in resnet.parameters():\n",
    "        conv_param.require_grad = False\n",
    "\n",
    "    # get the input dimension for this layer\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "\n",
    "    # build the new final mlp layers of network\n",
    "    fc = nn.Sequential(\n",
    "          nn.Linear(num_ftrs, num_ftrs),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(num_ftrs, 3)\n",
    "        )\n",
    "   \n",
    "    # replace final fully connected layer\n",
    "    resnet.fc = fc\n",
    "    return resnet\n",
    "\n",
    "# Model evaluation.\n",
    "@torch.no_grad()\n",
    "def eval_model(data_loader, model, loss_fn, DEVICE):\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    loss, accuracy = 0.0, 0.0\n",
    "    n = len(data_loader)\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        x,y = data\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x)\n",
    "        loss += loss_fn(pred, y)/len(x)\n",
    "        pred_label = torch.argmax(pred, axis = 1)\n",
    "        accuracy += torch.sum(pred_label == y)/len(x)\n",
    "\n",
    "    return loss/n, accuracy/n\n",
    "\n",
    "# loading checkpoint\n",
    "def load_checkpoint(checkpoint_path, DEVICE):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model_fm_checkpoint(checkpoint, primitive_model):\n",
    "    primitive_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return primitive_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d665d11",
   "metadata": {},
   "source": [
    "### Setup Process Group (1 and 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f64ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_distributed():\n",
    "    '''\n",
    "    set up process group with torchrun's environment variables\n",
    "    '''\n",
    "    # 1, 6 use os to get rank and world size\n",
    "    dist_url = \"env://\"\n",
    "    world_size = int(os.environ['WORLD_SIZE'])\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    dist.init_process_group(backend=\"nccl\", # \"nccl\" for using GPUs, \"gloo\" for using CPUs\n",
    "                          init_method=dist_url,\n",
    "                          world_size=world_size,\n",
    "                          rank=local_rank)\n",
    "    torch.cuda.set_device(local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc61024",
   "metadata": {},
   "source": [
    "### Create Data DistributedSampler (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.distributed import DistributedSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12044b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):\n",
    "    ##########################################################################################\n",
    "    # 2. Use Pytorch's DistributedSampler to ensure that data passed to each GPU is different\n",
    "\n",
    "    # create distributedsampler for train, validation and test sets\n",
    "    train_sampler = DistributedSampler(dataset=train_set,shuffle=shuffle)\n",
    "    val_sampler = DistributedSampler(dataset=val_set, shuffle=False)\n",
    "    test_sampler = DistributedSampler(dataset=test_set, shuffle=False) if test_set is not None else None\n",
    "\n",
    "    # pass distributedsampler for train, validation and test sets into DataLoader\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,sampler=train_sampler,num_workers=4,pin_memory=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_set,batch_size=batch_size,sampler=val_sampler,num_workers=4)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size, sampler=test_sampler,num_workers=4) if test_set is not None else None\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518ab26",
   "metadata": {},
   "source": [
    "### Write Checkpoints periodically during training and only from one device (4, 7C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, opt, scheduler, loss_fn, epochs, DEVICE, checkpoint_file, prev_best_val_acc):\n",
    "    n = len(train_loader)\n",
    "\n",
    "    best_val_acc = torch.tensor(0.0).to(DEVICE) if prev_best_val_acc is None else prev_best_val_acc\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(True)\n",
    "\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        avg_loss, val_loss, val_acc, avg_acc  = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred,y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            avg_loss += loss.item()/len(x)\n",
    "            pred_label = torch.argmax(pred, axis=1)\n",
    "            avg_acc += torch.sum(pred_label == y)/len(x)\n",
    "\n",
    "        val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        total_time = torch.tensor((end_time-start_time).seconds).to(DEVICE)\n",
    "\n",
    "        # Learning rate reducer takes action\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        avg_loss, avg_acc = avg_loss/n, avg_acc/n\n",
    "\n",
    "        ###############################################################################\n",
    "        # 4. Modify Training Loop to write model from one GPU     #####################\n",
    "        # 7C. Write checkpoints periodically throughout training. #####################\n",
    "        local_rank = int(os.environ['LOCAL_RANK'])\n",
    "        # Only machine rank==0 (master machine) saves the model and prints the metrics    \n",
    "        if local_rank == 0:\n",
    "\n",
    "          # Save the best model that has the highest val accuracy\n",
    "            if val_acc.item() > best_val_acc.item():\n",
    "                print(f'lr for this epoch is {scheduler.get_last_lr()}')\n",
    "                print(f\"\\nPrev Best Val Acc: {best_val_acc} < Cur Val Acc: {val_acc}\")\n",
    "                print(\"Saving the new best model...\")\n",
    "                torch.save({\n",
    "                    'epoch':epoch,\n",
    "                    'machine':local_rank,\n",
    "                    'model_state_dict':model.module.state_dict(),\n",
    "                    'accuracy':val_acc,\n",
    "                    'loss':val_loss\n",
    "                }, checkpoint_file)\n",
    "                best_val_acc = val_acc\n",
    "                print(\"Finished saving model\\n\")\n",
    "\n",
    "            # Print the metrics (should be same on all machines)\n",
    "            print(f\"\\n(Epoch {epoch+1}/{epochs}) Time: {total_time}s\")\n",
    "            print(f\"(Epoch {epoch+1}/{epochs}) Average train loss: {avg_loss}, Average train accuracy: {avg_acc}\")\n",
    "            print(f\"(Epoch {epoch+1}/{epochs}) Val loss: {val_loss}, Val accuracy: {val_acc}\")\n",
    "            print(f\"(Epoch {epoch+1}/{epochs}) Current best val acc: {best_val_acc}\\n\")\n",
    "        ###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f95fb",
   "metadata": {},
   "source": [
    "### Create Clean Up Function (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c337fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    print(\"Cleaning up the distributed environment...\")\n",
    "    dist.destroy_process_group()\n",
    "    print(\"Distributed environment has been properly closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4a96c",
   "metadata": {},
   "source": [
    "### Wrap Model with DDP and put everything together in main function (3, 6B, 7A, 7B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    hp = {\"lr\":1e-4, \"batch_size\":16, \"epochs\":5}\n",
    "    train_path = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Train/\")\n",
    "    val_path   = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Validation/\")\n",
    "    test_path  = None\n",
    "\n",
    "    #################################################\n",
    "    # 6B. Use pytorch's enviornment variables.  #####\n",
    "    local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    #################################################\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "    ###########################################################\n",
    "    # 7A. create location to store checkpoints if they did not exist. ##\n",
    "    \n",
    "    model_folder_path = os.path.join(os.environ['SCRATCH'], \"cnn4_damagelevel_output_model\") \n",
    "    os.makedirs(model_folder_path,exist_ok=True)\n",
    "    ###########################################################\n",
    "   \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1).to(DEVICE)\n",
    "    train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)\n",
    "    train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)\n",
    "\n",
    "    model = getResNet().to(DEVICE)\n",
    "    \n",
    "    \n",
    "    ######################################################################################\n",
    "    # 7B, Read check point if it exists and pass to the train function to resume training##\n",
    "    prev_best_val_acc = None\n",
    "    checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)\n",
    "        prev_best_val_acc = checkpoint['accuracy']\n",
    "        model = load_model_fm_checkpoint(checkpoint,model)\n",
    "        epoch_start = checkpoint['epoch']\n",
    "        if rank == 0:\n",
    "            print(f\"resuming training from epoch {epoch_start}\")\n",
    "        else:\n",
    "            epoch_start = 0\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    ##########################################################################\n",
    "    # 3. Wrap model with DDP #################################################\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "    ##########################################################################\n",
    "    opt = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "\n",
    "\n",
    "\n",
    "    # same learning rate scheduler as part 2\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min',factor=0.1, patience=5, min_lr=1e-8)\n",
    "\n",
    "    train(train_dataloader, val_dataloader, model, opt, scheduler, loss_fn, hp[\"epochs\"], DEVICE, checkpoint_file, prev_best_val_acc)\n",
    "\n",
    "    # only the node with rank 0 does the loading, evaluation and printing to avoild duplicate \n",
    "    if local_rank == 0:\n",
    "        # store and print info on the best model at the end of training\n",
    "        primitive_model = getResNet().to(DEVICE)\n",
    "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)\n",
    "        best_model = load_model_fm_checkpoint(checkpoint,primitive_model)\n",
    "        loss, acc = eval_model(val_dataloader,best_model,loss_fn,DEVICE)\n",
    "        print(f\"\\nBest model (val loss: {loss}, val accuracy: {acc}) has been saved to {checkpoint_file}\\n\")\n",
    "        ###############################\n",
    "        # 5. close process group ######\n",
    "        cleanup()\n",
    "        ###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5846857",
   "metadata": {},
   "source": [
    "Copy the DesignSafe dataset to your `$SCRATCH` If you had already copied the Dataset into your `$SCRATCH` folder (`$SCRATCH/Dataset_2`), you do not need to execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861757c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /scratch1/07980/sli4/training/cnn_course/data/data.tar.gz $SCRATCH\n",
    "! tar zxf $SCRATCH/data.tar.gz -C $SCRATCH\n",
    "! ls $SCRATCH/Dataset_2\n",
    "! rm $SCRATCH/data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66a08a",
   "metadata": {},
   "source": [
    "Launch the job with torchrun to train the designsafe classifier on a single node and 3 GPUs. Remove the previous model from $SCRATCH if you would like to start from epoch 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5df788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "# NOTE: This is the main script of using Distributed Data Parallel to train ResNet\n",
       "import sys\n",
       "import os\n",
       "import numpy as np\n",
       "import gc\n",
       "\n",
       "import torch\n",
       "import torchvision\n",
       "from torchvision import datasets, models, transforms\n",
       "import torch.nn as nn\n",
       "from torch.utils.data.distributed import DistributedSampler\n",
       "import torch.distributed as dist\n",
       "from datetime import datetime\n",
       "import warnings\n",
       "import shutil\n",
       "\n",
       "warnings.filterwarnings(\"ignore\", message=\"torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\")\n",
       "\n",
       "# Define the GPUs that will be used in this script\n",
       "os.environ['CUDA_VISIBLE_DEVICES'] = \",\".join(str(x) for x in list(range(torch.cuda.device_count())))\n",
       "\n",
       "# Apply transformations to our data.\n",
       "# The datasets transformations are the same as the ones from part 2 of this tutorial.\n",
       "def load_datasets(train_path, val_path, test_path):\n",
       "    val_img_transform = transforms.Compose([transforms.Resize((244,244)),\n",
       "                                         transforms.ToTensor()])\n",
       "    train_img_transform = transforms.Compose([transforms.AutoAugment(),\n",
       "                                           transforms.Resize((244,244)),\n",
       "                                           transforms.ToTensor()])\n",
       "    train_dataset = datasets.ImageFolder(train_path, transform=train_img_transform)\n",
       "    val_dataset = datasets.ImageFolder(val_path, transform=val_img_transform) \n",
       "    test_dataset = datasets.ImageFolder(test_path, transform=val_img_transform) if test_path is not None else None\n",
       "  \n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "    if local_rank == 0:\n",
       "        print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
       "    return train_dataset, val_dataset, test_dataset\n",
       "\n",
       "# Construct Dataloaders\n",
       "# The DistributedSampler we use here restricts data loading to a subset of the dataset.\n",
       "# In conjunction with DistributedDataParallel (shows up later in this tutorial), each process can pass a DistributedSampler instance as a DataLoader sampler, and load a subset of the original dataset that is exclusive to it.\n",
       "def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):  \n",
       "    train_sampler = DistributedSampler(dataset=train_set,shuffle=shuffle)\n",
       "    val_sampler = DistributedSampler(dataset=val_set, shuffle=False)\n",
       "    test_sampler = DistributedSampler(dataset=test_set, shuffle=False) if test_set is not None else None\n",
       "  \n",
       "    train_dataloader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,sampler=train_sampler,num_workers=4,pin_memory=True)\n",
       "    val_dataloader = torch.utils.data.DataLoader(val_set,batch_size=batch_size,sampler=val_sampler,num_workers=4)\n",
       "    test_dataloader = torch.utils.data.DataLoader(test_aset, batch_size, sampler=test_sampler,num_workers=4) if test_set is not None else None\n",
       "    \n",
       "    return train_dataloader, val_dataloader, test_dataloader\n",
       "\n",
       "\n",
       "# Building the Neural Network\n",
       "# This is the same from part 2 of this tutorial\n",
       "def getResNet():\n",
       "    resnet = models.resnet34(weights='IMAGENET1K_V1')\n",
       "\n",
       "    # Fix the conv layers parameters\n",
       "    for conv_param in resnet.parameters():\n",
       "        conv_param.require_grad = False\n",
       "\n",
       "    # get the input dimension for this layer\n",
       "    num_ftrs = resnet.fc.in_features\n",
       "    \n",
       "    # build the new final mlp layers of network\n",
       "    fc = nn.Sequential(\n",
       "          nn.Linear(num_ftrs, num_ftrs),\n",
       "          nn.ReLU(),\n",
       "          nn.Linear(num_ftrs, 3)\n",
       "        )\n",
       "    \n",
       "    # replace final fully connected layer\n",
       "    resnet.fc = fc\n",
       "    return resnet\n",
       "\n",
       "\n",
       "# Model evaluation.\n",
       "# This is implemented in the same way as part 2 of this tutorial.\n",
       "@torch.no_grad()\n",
       "def eval_model(data_loader, model, loss_fn, DEVICE):\n",
       "    model.train(False)\n",
       "    model.eval()\n",
       "    loss, accuracy = 0.0, 0.0\n",
       "    n = len(data_loader)\n",
       "    \n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "\n",
       "    for i, data in enumerate(data_loader):\n",
       "        x,y = data\n",
       "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
       "        pred = model(x)\n",
       "        loss += loss_fn(pred, y)/len(x)\n",
       "        pred_label = torch.argmax(pred, axis = 1)\n",
       "        accuracy += torch.sum(pred_label == y)/len(x)\n",
       "    \n",
       "    return loss/n, accuracy/n\n",
       "\n",
       "\n",
       "# Model training.\n",
       "# This is implemented in the same way as part 2 of this tutorial.\n",
       "def train(train_loader, val_loader, model, opt, scheduler, loss_fn, epoch_start, epochs, DEVICE, checkpoint_file, prev_best_val_acc):\n",
       "    n = len(train_loader)\n",
       "\n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "  \n",
       "    best_val_acc = torch.tensor(0.0).to(DEVICE) if prev_best_val_acc is None else prev_best_val_acc\n",
       "    \n",
       "    for epoch in range(epoch_start, epochs):\n",
       "        model.train(True)\n",
       "    \n",
       "        train_loader.sampler.set_epoch(epoch)\n",
       "    \n",
       "        avg_loss, val_loss, val_acc, avg_acc  = 0.0, 0.0, 0.0, 0.0\n",
       "    \n",
       "        start_time = datetime.now()\n",
       "    \n",
       "        for x, y in train_loader:\n",
       "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
       "            pred = model(x)\n",
       "            loss = loss_fn(pred,y)\n",
       "            \n",
       "            opt.zero_grad()\n",
       "            loss.backward()\n",
       "            opt.step()\n",
       "\n",
       "            avg_loss += loss.item()/len(x)\n",
       "            pred_label = torch.argmax(pred, axis=1)\n",
       "            avg_acc += torch.sum(pred_label == y)/len(x)\n",
       "\n",
       "\n",
       "        val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
       "    \n",
       "        end_time = datetime.now()\n",
       "    \n",
       "        total_time = torch.tensor((end_time-start_time).seconds).to(DEVICE)\n",
       "    \n",
       "        # Learning rate reducer takes action\n",
       "        scheduler.step(val_loss)\n",
       "    \n",
       "        avg_loss, avg_acc = avg_loss/n, avg_acc/n\n",
       "    \n",
       "        # Only machine rank==0 (master machine) saves the model and prints the metrics    \n",
       "        if local_rank == 0:\n",
       "        \n",
       "            # Save the best model that has the highest val accuracy\n",
       "            if val_acc.item() > best_val_acc.item():\n",
       "                print(f'\\nlr for this epoch is {scheduler.get_last_lr()}')\n",
       "                print(f\"Prev Best Val Acc: {best_val_acc} < Cur Val Acc: {val_acc}\")\n",
       "                print(\"Saving the new best model...\")\n",
       "                torch.save({\n",
       "                        'epoch':epoch,\n",
       "                        'machine':local_rank,\n",
       "                        'model_state_dict':model.module.state_dict(),\n",
       "                        'accuracy':val_acc,\n",
       "                        'loss':val_loss\n",
       "                }, checkpoint_file)\n",
       "                best_val_acc = val_acc\n",
       "                print(\"Finished saving model\\n\")\n",
       "        \n",
       "            # Print the metrics (should be same on all machines)\n",
       "            print(f\"\\n(Epoch {epoch+1}/{epochs}) Time: {total_time}s\")\n",
       "            print(f\"(Epoch {epoch+1}/{epochs}) Average train loss: {avg_loss}, Average train accuracy: {avg_acc}\")\n",
       "            print(f\"(Epoch {epoch+1}/{epochs}) Val loss: {val_loss}, Val accuracy: {val_acc}\")  \n",
       "            print(f\"(Epoch {epoch+1}/{epochs}) Current best val acc: {best_val_acc}\\n\")  \n",
       "\n",
       "def load_checkpoint(checkpoint_path, DEVICE):\n",
       "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
       "    return checkpoint\n",
       "\n",
       "def load_model_fm_checkpoint(checkpoint, primitive_model):\n",
       "    primitive_model.load_state_dict(checkpoint['model_state_dict'])\n",
       "    return primitive_model \n",
       "\n",
       "def init_distributed():\n",
       "    \n",
       "    dist_url = \"env://\"\n",
       "  \n",
       "    world_size = int(os.environ['WORLD_SIZE']) \n",
       "    local_rank = int(os.environ['LOCAL_RANK']) \n",
       "    dist.init_process_group(backend=\"nccl\", #\"nccl\" for using GPUs, \"gloo\" for using CPUs\n",
       "                            init_method=dist_url,\n",
       "                            world_size=world_size,\n",
       "                            rank=local_rank)\n",
       "    torch.cuda.set_device(local_rank)\n",
       "\n",
       "\n",
       "def cleanup():\n",
       "    print(\"Cleaning up the distributed environment...\")\n",
       "    dist.destroy_process_group()\n",
       "    print(\"Distributed environment has been properly closed\")\n",
       "    \n",
       "    \n",
       "def main():\n",
       "    hp = {\"lr\":1e-4, \"batch_size\":16, \"epochs\":5}\n",
       "    \n",
       "    # Please specify the path to train, cross_validation, and test images below:\n",
       "    train_path = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Train/\")\n",
       "    val_path   = os.path.join(os.environ['SCRATCH'], \"Dataset_2/Validation/\")\n",
       "    test_path  = None\n",
       "    \n",
       "    local_rank = int(os.environ['LOCAL_RANK'])\n",
       "    DEVICE = torch.device(\"cuda\", local_rank)\n",
       "    \n",
       "    model_folder_path = os.path.join(os.environ['SCRATCH'], \"cnn4_damagelevel_output_model\") \n",
       "    os.makedirs(model_folder_path,exist_ok=True)\n",
       "    \n",
       "    # same loss function as part 2 \n",
       "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1).to(DEVICE)\n",
       "    train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)\n",
       "    train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)\n",
       "                          \n",
       "    model = getResNet().to(DEVICE)\n",
       "  \n",
       "    # load the checkpoint that has the best performance in previous experiments\n",
       "    prev_best_val_acc = None\n",
       "    checkpoint_file = os.path.join(model_folder_path, \"best_model.pt\")\n",
       "    if os.path.exists(checkpoint_file):\n",
       "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)\n",
       "        prev_best_val_acc = checkpoint['accuracy']\n",
       "        model = load_model_fm_checkpoint(checkpoint,model)\n",
       "        epoch_start = checkpoint['epoch']\n",
       "        if local_rank == 0:\n",
       "            print(f\"resuming training from epoch {epoch_start}\")\n",
       "    else:\n",
       "        epoch_start = 0\n",
       "  \n",
       "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
       "    model = nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
       "    opt = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
       "    \n",
       "    # same learning rate scheduler as part 2\n",
       "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min',factor=0.1, patience=5, min_lr=1e-8)\n",
       "  \n",
       "    train(train_dataloader, val_dataloader, model, opt, scheduler, loss_fn, epoch_start, hp[\"epochs\"], DEVICE, checkpoint_file, prev_best_val_acc)\n",
       "   \n",
       "\n",
       "  # only the node with rank 0 does the loading, evaluation and printing to avoild duplicate \n",
       "    if local_rank == 0:\n",
       "        primitive_model = getResNet().to(DEVICE)\n",
       "        checkpoint = load_checkpoint(checkpoint_file, DEVICE)\n",
       "        best_model = load_model_fm_checkpoint(checkpoint,primitive_model)\n",
       "        loss, acc = eval_model(val_dataloader,best_model,loss_fn,DEVICE)\n",
       "        print(f\"\\nBest model (val loss: {loss}, val accuracy: {acc}) has been saved to {checkpoint_file}\\n\")\n",
       "        cleanup()\n",
       "\n",
       "if __name__ == '__main__':\n",
       "    init_distributed()\n",
       "    \n",
       "    gc.collect()\n",
       "    for i in range(torch.cuda.device_count()):\n",
       "        with torch.cuda.device(f\"cuda:{i}\"):\n",
       "            torch.cuda.empty_cache()\n",
       "  \n",
       "    main()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_python(\"cnn_part4/torch_train_distributed.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc-per-node=4 cnn_part4/torch_train_distributed.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
